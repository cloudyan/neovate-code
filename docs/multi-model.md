# 多模型智能协同

灵活切换和组合使用多个 AI 模型，发挥各自优势

- https://github.com/shareAI-lab/Kode/blob/main/README.zh-CN.md

与 CC 仅支持单一模型不同，Kode 实现了**真正的多模型协同工作**，让你能够充分发挥不同 AI 模型的独特优势。

### 🏗️ 核心技术架构

#### 1. **ModelManager 多模型管理器**
我们设计了统一的 `ModelManager` 系统，支持：
- **模型配置文件（Model Profiles）**：每个模型都有独立的配置文件，包含 API 端点、认证信息、上下文窗口大小、成本等参数
- **模型指针（Model Pointers）**：用户可以在 `/model` 命令中配置不同用途的默认模型：
  - `main`：主 Agent 的默认模型
  - `task`：SubAgent 的默认模型
  - `reasoning`：预留给未来 ThinkTool 使用
  - `quick`：用于简单 NLP 任务（如安全性识别、生成标题描述等）的快速模型
- **动态模型切换**：支持运行时切换模型，无需重启会话，保持上下文连续性

#### 2. **TaskTool 智能任务分发工具**
专门设计的 `TaskTool`（Architect 工具）实现了：
- **Subagent 机制**：可以启动多个子代理并行处理任务
- **模型参数传递**：用户可以在请求中指定 SubAgent 使用的模型
- **默认模型配置**：SubAgent 默认使用 `task` 指针配置的模型

#### 3. **AskExpertModel 专家咨询工具**
我们专门设计了 `AskExpertModel` 工具：
- **专家模型调用**：允许在对话中临时调用特定的专家模型解决疑难问题
- **模型隔离执行**：专家模型的响应独立处理，不影响主对话流程
- **知识整合**：将专家模型的见解整合到当前任务中

#### 🎯 灵活的模型切换
- **Tab 键快速切换**：在输入框按 Tab 键即可快速切换当前对话使用的模型
- **`/model` 命令**：使用 `/model` 命令配置和管理多个模型配置文件，设置不同用途的默认模型
- **用户控制**：用户可以随时指定使用特定的模型进行任务处理

#### 🔄 智能的工作分配策略

**架构设计阶段**
- 使用 **o3 模型** 或 **GPT-5 模型** 探讨系统架构，制定犀利明确的技术方案
- 这些模型在抽象思维和系统设计方面表现卓越

**方案细化阶段**
- 使用 **gemini 模型** 深入探讨生产环境的设计细节
- 利用其在实际工程实践中的深厚积累和平衡的推理能力

**代码实现阶段**
- 使用 **Qwen Coder 模型**、**Kimi k2 模型** 、**GLM-4.5 模型** 或 **Claude Sonnet 4 模型** 进行具体的代码编写
- 这些模型在代码生成、文件编辑和工程实现方面性能强劲
- 支持通过 subagent 并行处理多个编码任务

**疑难问题解决**
- 遇到复杂问题时，可单独咨询 **o3 模型**、**Claude Opus 4.1 模型** 或 **Grok 4 模型** 等专家模型
- 获得深度的技术见解和创新的解决方案

#### 💡 实际应用场景

```bash
# 示例 1：架构设计
"用 o3 模型帮我设计一个高并发的消息队列系统架构"

# 示例 2：多模型协作
"先用 GPT-5 模型分析这个性能问题的根本原因，然后用 Claude Sonnet 4 模型编写优化代码"

# 示例 3：并行任务处理
"用 Qwen Coder 模型作为 subagent 同时重构这三个模块"

# 示例 4：专家咨询
"这个内存泄漏问题很棘手，单独问问 Claude Opus 4.1 模型有什么解决方案"

# 示例 5：代码审查
"让 Kimi k2 模型审查这个 PR 的代码质量"

# 示例 6：复杂推理
"用 Grok 4 模型帮我推导这个算法的时间复杂度"

# 示例 7：方案设计
"让 GLM-4.5 模型设计微服务拆分方案"
```

### 🛠️ 关键实现机制

#### **配置系统（Configuration System）**
```typescript
// 支持多模型配置的示例
{
  "modelProfiles": {
    "o3": { "provider": "openai", "model": "o3", "apiKey": "..." },
    "claude4": { "provider": "anthropic", "model": "claude-sonnet-4", "apiKey": "..." },
    "qwen": { "provider": "alibaba", "model": "qwen-coder", "apiKey": "..." }
  },
  "modelPointers": {
    "main": "claude4",      // 主对话模型
    "task": "qwen",         // 任务执行模型
    "reasoning": "o3",      // 推理模型
    "quick": "glm-4.5"      // 快速响应模型
  }
}
```

#### **成本追踪系统（Cost Tracking）**
- **使用统计**：`/cost` 命令查看各模型的 token 使用量和花费
- **多模型成本对比**：实时追踪不同模型的使用成本
- **历史记录**：保存每个会话的成本数据

#### **上下文管理器（Context Manager）**
- **上下文继承**：切换模型时保持对话连续性
- **上下文窗口适配**：根据不同模型的上下文窗口大小自动调整
- **会话状态保持**：确保多模型协作时的信息一致性

### 🚀 多模型协同的优势

1. **效率最大化**：每个任务都由最适合的模型处理
2. **成本优化**：简单任务用轻量模型，复杂任务用强大模型
3. **并行处理**：多个模型可以同时处理不同的子任务
4. **灵活切换**：根据任务需求随时切换模型，无需重启会话
5. **取长补短**：结合不同模型的优势，获得最佳的整体效果

### 📊 与官方实现的对比

| 特性 | Kode | 官方 CC |
|------|------|---------|
| 支持模型数量 | 无限制，可配置任意模型 | 仅支持单一 Claude 模型 |
| 模型切换 | ✅ Tab 键快速切换 | ❌ 需要重启会话 |
| 并行处理 | ✅ 多个 SubAgent 并行工作 | ❌ 单线程处理 |
| 成本追踪 | ✅ 多模型成本分别统计 | ❌ 单一模型成本 |
| 任务模型配置 | ✅ 不同用途配置不同默认模型 | ❌ 所有任务用同一模型 |
| 专家咨询 | ✅ AskExpertModel 工具 | ❌ 不支持 |

这种多模型协同能力让 Kode 成为真正的 **AI 开发工作台**，而不仅仅是一个单一的 AI 助手。

## 其他

常见模型

1. qwen3-coder 非常适合代码分析和生成任务
2. kimi-k2 适用于一般的人工智能任务和更长的上下文处理
3. deepseek-v3 高级推理和复杂问题解决

| 场景需求               | 优先推荐模型                        | 核心优势                                   | 备选/轻量方案                |
| ------------------ | ----------------------------- | -------------------------------------- | ---------------------- |
| 中文创意写作、营销文案        | 文心一言 ERNIE 4.0                | 中文成语、古文、广告金句生成质量最高                | 豆包、智谱清言                |
| 英文/多语种长文档总结        | Claude 3.7 Sonnet             | 200k token 一次读完，合规性高，价格低 GPT-4 一半 | GPT-4.1                |
| 复杂代码补全、跨文件调试       | GPT-4.1 / Claude Opus 4       | 代理模式可自动遍历代码库，架构级重构                | o3 / Claude Sonnet 3.7 |
| 快速简单脚本、单元测试        | o4-mini / GPT-4o mini         | 延迟＜300 ms，成本↓80%             | Codex-mini             |
| 语音对话、实时翻译          | GPT-4o Audio                  | 原生语音↔语音，情绪识别准                     | Whisper v3             |
| 文生图、海报、插画          | DALL·E 3 / GPT Image 1        | 文字渲染无乱码，支持 PSD 分层下载          | Midjourney v6          |
| 多模态“图+文”问答         | Qwen-VL-70B                   | 看懂梗图、数理化图片推理解题                    | Gemini 2.5 Pro         |
| 医疗诊断辅助             | 华佗 GPT / 扁鹊-7B                | 中文医学知识图谱增强，支持 ICD-10 编码           | Claude 3.7（合规审查）       |
| 法律文书、合同审查          | LaWGPT-13B / Claude 3.7       | 法条引用准确率 96%，支持电子签章格式         | 文心一言（通用版）              |
| 金融风控、研报生成          | BloombergGPT-50B / 轩辕-13B     | 实时接入 Wind/同花顺 API，指标计算零误差         | GPT-4.1 + 插件           |
| 长文本（>128 k）摘要、论文精读 | LLaMA 3.1-70B / 元象 XVERSE-13B | 支持 200 k 上下文，指令服从度高          | Claude 3.7             |
| 边缘设备离线部署           | Phi-2-2.7B                    | 可在树莓派 4B 运行，医疗、教育隐私合规             | Qwen-1.8B              |
